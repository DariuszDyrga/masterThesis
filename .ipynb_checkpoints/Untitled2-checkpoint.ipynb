{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58559a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import scipy.io\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e09238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('StenosisDetection/train_labels.csv', usecols=['filename','xmax','ymax','xmin', 'ymin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49be3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca58cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = [], []\n",
    "top_left_x_collection = []\n",
    "top_left_y_collection = []\n",
    "bottom_right_x_collection = []\n",
    "bottom_right_y_collection = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f43d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    image = keras.utils.load_img(\n",
    "        'StenosisDetection/dataset/'+row['filename'],\n",
    "    )\n",
    "\n",
    "    (w, h) = image.size[:2]\n",
    "    image = image.resize((640, 640))\n",
    "    images.append(keras.utils.img_to_array(image))\n",
    "    \n",
    "    \n",
    "    top_left_x, top_left_y = row['xmax'], row['ymax']\n",
    "    bottom_right_x, bottom_right_y = row['xmin'], row['ymin']\n",
    "    \n",
    "    targets.append(\n",
    "        (\n",
    "            float(top_left_x) / w,\n",
    "            float(top_left_y) / h,\n",
    "            float(bottom_right_x) / w,\n",
    "            float(bottom_right_y) / h,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aea62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('StenosisDetection/test_labels.csv', usecols=['filename','xmax','ymax','xmin', 'ymin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, targets_test = [], [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_test.iterrows():\n",
    "    image = keras.utils.load_img(\n",
    "        'StenosisDetection/dataset/'+row['filename'],\n",
    "    )\n",
    "\n",
    "    (w, h) = image.size[:2]\n",
    "    image = image.resize((640, 640))\n",
    "    images_test.append(keras.utils.img_to_array(image))\n",
    "    \n",
    "    \n",
    "    top_left_x, top_left_y = row['xmax'], row['ymax']\n",
    "    bottom_right_x, bottom_right_y = row['xmin'], row['ymin']\n",
    "    \n",
    "    targets_test.append(\n",
    "        (\n",
    "            float(top_left_x) / w,\n",
    "            float(top_left_y) / h,\n",
    "            float(bottom_right_x) / w,\n",
    "            float(bottom_right_y) / h,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328f04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train), (y_train) = (\n",
    "    np.asarray(images[: int(len(images))]),\n",
    "    np.asarray(targets[: int(len(targets))]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10890ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_test), (y_test) = (\n",
    "    np.asarray(images_test[: int(len(images_test))]),\n",
    "    np.asarray(targets_test[: int(len(targets_test))]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948343af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650335bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy scipy scikit-image matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51196c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f469be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = torchvision.models.detection.ssd300_vgg16(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68477a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import smooth_l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_loader = torch.utils.data.DataLoader(x_train, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5370d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import smooth_l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwertuj dane na tensory PyTorch\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Utwórz instancję optymalizatora SGD i przekaż do niego parametry do optymalizacji z modelu\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Przygotuj pętlę treningową i wykonaj kilka epok treningu\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd206959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(x_train_tensor)):\n",
    "        # Przekaż dane wejściowe do modelu i uzyskaj predykcje wyjściowe\n",
    "        inputs = x_train_tensor[i].unsqueeze(0)\n",
    "        targets = y_train_tensor[i].unsqueeze(0)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Oblicz wartość funkcji straty pomiędzy predykcjami a oczekiwanymi wartościami\n",
    "        loss = smooth_l1_loss(outputs, targets)\n",
    "\n",
    "        # Wyczyszczenie gradientów\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Oblicz gradienty funkcji straty wstecznie\n",
    "        loss.backward()\n",
    "\n",
    "        # Zastosuj optymalizację gradientową do parametrów modelu\n",
    "        optimizer.step()\n",
    "\n",
    "        # Aktualizuj bieżący stan funkcji straty\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Wyświetl informacje o postępie treningu\n",
    "    print('Epoch [%d/%d], Loss: %.4f' % (epoch+1, num_epochs, running_loss/len(x_train_tensor)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
